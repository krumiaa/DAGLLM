#DAG-LLM Pipeline (Reference Release)
From Fuzzy Worlds to Causal Graphs
This repository provides a minimal reference implementation of the DAG-LLM Pipeline â€” a method for converting unstructured text into causal directed acyclic graphs (DAGs). It demonstrates how large language models (LLMs), which encode fuzzy and probabilistic human world models, can be transformed into explicit, explainable, and structured causal graphs.
The codebase is designed for reproducibility and research.
________________


âœ¨ Features
* Backend Service (FastAPI): Ingest journal text, extract entities & relations with GPT, and store results in SQLite.

* Graph Models: Structured database schema for agents, entities, edges, and journal entries.

* Visualization: Example DAGs rendered with NetworkX + Matplotlib.

* Frontend (ReactFlow demo): Minimal graph viewer in App.js.

* Open Reference Implementation: Lightweight, extensible, and easy to adapt for research.

________________


ğŸ“‚ Repository Structure
.
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ db.py                # Database schema (Agent, Entity, Edge, JournalEntry)
â”‚   â””â”€â”€ gpt_maindb.py        # FastAPI service for ingestion + DAG extraction
â”œâ”€â”€ create_db.py             # Initialize SQLite database
â”œâ”€â”€ send_journal_gpt_db.py   # Example script: ingest text + visualize DAG
â””â”€â”€ sample_journal.txt       # Example text for testing


________________


ğŸš€ Getting Started
1. Clone Repository
git clone https://github.com/your-username/dag-llm-pipeline.git
cd dag-llm-pipeline


2. Set Up Backend
Create a virtual environment and install dependencies:
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
pip install -r requirements.txt


Initialize the database:
python create_db.py


Run the FastAPI backend:
uvicorn api.gpt_maindb:app --reload --port 8001


3. Set OpenAI API Key
Export your API key (or edit .env):
export OPENAI_API_KEY=your_api_key_here


4. Visualize a Sample Journal
Run the demo script:
python send_journal_gpt_db.py


This will:
   * Ingest sample_journal.txt

   * Store entities & edges in SQLite

   * Render the resulting DAG with NetworkX/Matplotlib


ğŸ“– Example Output
Given the input text:
â€œI feel nervous because I failed my last interview. I want a strategy to increase confidence.â€
The pipeline extracts nodes and edges such as:
Nodes: ["I", "nervousness", "last_interview_failure", "confidence", "strategy"]
Edges:
- last_interview_failure â†’ nervousness (causes)
- nervousness â†’ confidence (reduces)
- strategy â†’ confidence (increases)


And renders a DAG showing the causal structure.
